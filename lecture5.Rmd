---
title: CS5014 Machine Learning
subtitle: Lecture 5 Maximum Likelihood Estimation (MLE) 
author: "Lei Fang"
date: Spring 2021
output: 
  beamer_presentation:
    df_print: "kable"
    keep_tex: false
#    toc: true
#    slide_level: 3
    includes:
      in_header: 
        - ./preambles/sta-beamer-header-simple.tex
        - ./preambles/l5.tex
        # - title-page.tex
#      after_body: ~/Dropbox/teaching/table-of-contents.txt
bibliography: "ref.bib"
---


```{r setup, include=FALSE}
library(rgl)
knitr::opts_chunk$set(webgl = hook_webgl,
                      echo = FALSE,
                      fig.align = 'center',
                      message =FALSE,
                      warning = FALSE
                      )

```

```{r, include= FALSE}
##################################################################
# gbinom is a function for graphing the binomial distribution.   #
# two parameters are necessary: the number n of trials and the   #
# probability p of succes. Other options are optional.           #
# copied from http://pages.stat.wisc.edu/~larget/R/prob.R        #
##################################################################

gbinom = function(n, p, low=0, high=n,scale = F, a=NA,b=NA,calcProb=!all(is.na(c(a,b))),quantile=NA,calcQuant=!is.na(quantile))
{
  sd = sqrt(n * p * (1 - p))
  if(scale && (n > 10)) {
	low = max(0, round(n * p - 4 * sd))
	high = min(n, round(n * p + 4 * sd))
  }
  values = low:high
  probs = dbinom(values, n, p)
  plot(c(low,high), c(0,max(probs)), type = "n", xlab = "Possible Values",
      ylab = "Probability",
      main = paste("Binomial Distribution \n", "n =", n, ", p =", p))
  lines(values, probs, type = "h", col = 2)
  abline(h=0,col=3)
  if(calcProb) {
    if(is.na(a))
      a = 0
    if(is.na(b))
      b = n
    if(a > b) {
      d = a
      a = b
      b = d
    }
    a = round(a)
    b = round(b)
    prob = pbinom(b,n,p) - pbinom(a-1,n,p)
    title(paste("P(",a," <= Y <= ",b,") = ",round(prob,6),sep=""),line=0,col.main=4)
    u = seq(max(c(a,low)),min(c(b,high)),by=1)
    v = dbinom(u,n,p)
    lines(u,v,type="h",col=4)
  }
  else if(calcQuant==T) {
    if(quantile < 0 || quantile > 1)
      stop("quantile must be between 0 and 1")
    x = qbinom(quantile,n,p)
    title(paste("The ",quantile," quantile = ",x,sep=""),line=0,col.main=4)
    u = 0:x
    v = dbinom(u,n,p)
    lines(u,v,type="h",col=4)
  }
  return(invisible())
}

#######################################################################
# gpois is a function for graphing the Poisson distribution.          #
# One parameter is necessary: the mean mu. Other options are optional.#
#######################################################################

gpois = function(mu, a=NA,b=NA,calcProb=(!is.na(a) | !is.na(b)),quantile=NA,calcQuant=!is.na(quantile))
{
  sd = sqrt(mu)
  low = max(0, round(mu - 3 * sd))
  high = round(mu + 5 * sd)
  values = low:high
  probs = dpois(values, mu)
  plot(c(low,high), c(0,max(probs)), type = "n", xlab = "observable values",
      ylab = "Probability",
      main =substitute(paste("Poisson Distribution with ",mu==m), list(m=mu)))
  lines(values, probs, type = "h", col = 2)
  abline(h=0,col=3)
  if(calcProb) {
    if(is.na(a)){ a = 0 }
    if(is.na(b)){
     a = round(a)
     prob = 1-ppois(a-1,mu)
     title(paste("P(",a," <= Y ) = ",round(prob,6),sep=""),line=0,col.main=4)
     u = seq(max(c(a,low)),high,by=1)
    }
    else {
     if(a > b) {d = a; a = b; b = d;}
     a = round(a); b = round(b)
     prob = ppois(b,mu) - ppois(a-1,mu)
     title(paste("P(",a," <= Y <= ",b,") = ",round(prob,6),sep=""),line=0,col.main=4)
     u = seq(max(c(a,low)),min(c(b,high)),by=1)
    }
    v = dpois(u,mu)
    lines(u,v,type="h",col=4)
  }
  else if(calcQuant==T) {
    if(quantile < 0 || quantile > 1)
      stop("quantile must be between 0 and 1")
    x = qpois(quantile,mu)
    title(paste("The ",quantile," quantile = ",x,sep=""),line=0,col.main=4)
    u = 0:x
    v = dpois(u,mu)
    lines(u,v,type="h",col=4)
  }
  return(invisible())
}

#####################################################################
# gnorm plots normal curves and computes and displays probabilities #
# two parameters are necessary: the mean mu and standard            #
# deviation sigma. Others options are available but optional only.  #
#####################################################################

gnorm = function(mu, sigma,a=NA,b=NA,calcProb=!all(is.na(c(a,b))),quantile=NA,calcQuant=!is.na(quantile))
{
  values = seq(-1,1,.005) * 4 * sigma + mu
  probs = dnorm(values, mu, sigma)
  plot(values, probs, axes = F, type = "n", xlab = "Possible Values", 
    ylab = "Probability Density",
    main = substitute(paste("Normal Distribution with ",mu == m,", ",sigma == s),list(m=mu,s=sigma)))
  axis(1, pos = 0)
  abline(0,0,col=1)
  lines(values, probs, col = 2)
  lo = mu - 4 * sigma
  hi = mu + 4 * sigma
  h = dnorm(mu,mu,sigma)
  cex=0.8
  if(calcProb==T)
  {
    if(!is.na(a) && !is.na(b) && a > b){
      d = a; a = b; b = d
    }
    if(is.na(a) || a <= lo){ ulo = lo }
    else if(a <= hi){ ulo = a }
    else { ulo = hi }
    if(is.na(b) || b >= hi){ uhi = hi }
    else if(b >= lo){ uhi = b }
    else { uhi = lo }
    u = seq(ulo,uhi,length=601)
    lines(u,dnorm(u,mu,sigma),type="h",col=2)
    if(!is.na(a) && !is.na(b)){
      text(mu - 3.9 * sigma, 0.8 * h,
        paste("P( ",a," < X < ",b," ) = ",
  	round(pnorm(b,mu,sigma)-pnorm(a,mu,sigma),digits=4),sep=""),
        adj=0,col=4,cex=cex)
      text(mu - 3.9 * sigma, 0.6 * h,
        paste("P( X < ",a," ) = ",
          round(pnorm(a,mu,sigma),digits=4),sep=""),adj=0,col=4,cex=cex)
      text(mu + 3.9 * sigma, 0.5 * h,
        paste("P( X > ",b," ) = ",
       	round(1-pnorm(b,mu,sigma),digits=4),sep=""),adj=1,col=4,cex=cex)
    }
    else if(!is.na(a) && is.na(b)){
      text(mu - 3.9 * sigma, 0.6 * h,
        paste("P( X < ",a," ) = ",
          round(pnorm(a,mu,sigma),digits=4),sep=""),adj=0,col=4,cex=cex)
      text(mu + 3.9 * sigma, 0.5 * h,
        paste("P( X > ",a," ) = ",
       	round(1-pnorm(a,mu,sigma),digits=4),sep=""),adj=1,col=4,cex=cex)
    }
    else if(is.na(a) && !is.na(b)){
      text(mu - 3.9 * sigma, 0.6 * h,
        paste("P( X < ",b," ) = ",
          round(pnorm(b,mu,sigma),digits=4),sep=""),adj=0,col=4,cex=cex)
      text(mu + 3.9 * sigma, 0.5 * h,
        paste("P( X > ",b," ) = ",
       	round(1-pnorm(b,mu,sigma),digits=4),sep=""),adj=1,col=4,cex=cex)
    }
  }
  else if(calcQuant==T)
  {
    zoffset = -0.02
    if( quantile <= 0 || quantile >= 1) quantile = 0.5
    x = qnorm(quantile,mu,sigma)
    if( x > lo && x < hi)
    {
      u = seq(lo,x,length=601)
      lines(u,dnorm(u,mu,sigma),type="h",col=2)
      text(x, zoffset * h,
  	paste("z = ",round(qnorm(quantile),2),sep=""),adj=0.5,col=4,cex=cex)
    }
    else if(x >= hi)
    {
      u = seq(lo,hi,length=601)
      lines(u,dnorm(u,mu,sigma),type="h",col=2)
      text(hi, zoffset * h,
  	paste("z = ",round(qnorm(quantile),2),sep=""),adj=0.5,col=4,cex=cex)
    }
    else if( x <= lo)
    {
      text(lo, zoffset * h,
  	paste("z = ",round(qnorm(quantile),2),sep=""),adj=0.5,col=4,cex=cex)
    }
    text(mu - 3.9 * sigma, 0.5 * h,
      paste("P( X < ",signif(x,4)," ) = ",
  	round(quantile,digits=4),sep=""),adj=0,col=4,cex=cex)
  }
  return(invisible())
}


######################## next functions for fun ###################
#
# graph a skewed sampling distribution
gskew = function(n = 1, mu = 0, sd = 1, skew = 0)
{
	se = sd/sqrt(n)
	x = seq(mu - 4 * se, mu + 4 * se, length = 501)
	y = dskew(x, n, mu, sd, skew)
	plot(x, y, xlab = "", ylab = "density", 
		main = paste("Distribution of x-bar, sample size =",n), type = "n")
	lines(x, y, type = "l", col = 4)
	abline(h = 0)
	lines(x, dnorm(x, mu, se), col = 5)
	return(invisible(y))
}

# density of skewed distribution
dskew = function(x, n = 1, mu = 0, sd = 1, skew = 0)
{
	se = sd/sqrt(n)
	if(skew == 0)
		y = dnorm(x, mu, se)
	else {
		a = (skew * sd)/2
		b = mu - (2 * sd)/skew
		alpha = 4/skew/skew
		if(skew > 0)
			y = (n * dgamma((n * (x - b))/a, n * alpha))/a
		else y = ( - n * dgamma((n * (x - b))/a, n * alpha))/a
	}
	return(y)
}

# density of symmetric bimodal distribution
dbimod = function(x,n=1,mu=0,sd=1,d=1)
{
	if(d >= sd)
		stop("sd must be larger than d")
	temp = matrix(0,nrow=n+1,ncol=length(x))
	for(i in 0:n){temp[i+1,] = dbinom(i,n,.5)*dnorm(x,mu-d+2*i*d/n,sqrt((sd*sd-d*d)/n))}
	return(apply(temp,2,sum))
}

# graph sampling distribution of symmetric bimodal distribution
gbimod = function(n=1, mu=0, sd=1, d=0.5)
{
	if(d >= sd)
		stop("sd must be larger than d")
	se = sd/sqrt(n)
	x = seq(mu - 4 * se, mu + 4 * se, length = 201)
	y = dbimod(x, n, mu, sd, d)
	xx = c(mu - 4 * se, mu + 4 * se)
	yy = c(0, max(y, dnorm(mu, mu, se)))
	plot(xx, yy, xlab = "", ylab = "density", 
		main = paste("Distribution of x-bar, sample size =",n), type = "n")
	lines(x, y, type = "l", col = 4)
	abline(h = 0)
	lines(x, dnorm(x, mu, se), col = 5)
	return(invisible(y))
}

```



```{r, include = FALSE}
library(tidyverse)
library(reticulate)
matplotlib <- import("matplotlib", convert = TRUE)
matplotlib$use("Agg")
write_matex2 <- function(x) {
  begin <- "\\begin{bmatrix}"
  end <- "\\end{bmatrix}"
  X <-
    apply(x, 1, function(x) {
      paste(
        paste(round(x,2), collapse = "&"),
        "\\\\"
      )
    })
  paste(c(begin, X, end), collapse = "")
}
```






# Introduction

## Motivation

Objective: **probabilistic perspective** of linear regression

  - justify least squared error: $(\vv{y} - \vv{X\theta})^T(\vv{y}-\vv{X\theta})$ 
  - maximum likelihood estimator: $\vv{\theta}_{\text{ML}}$
  - BUT nothing new: $\vv{\theta}_{\text{ML}} = \vv{\theta}_{\text{LS}} = (\vv{XX})^{-1}\vv{Xy}$
  
\bigskip 
\pause 
So why bother ?  

  - MLE: very general model
  - lots of ML algorithms fit in MLE category
    - linear regression, logistic regression, k-means, mixture model, neural nets, discriminant analysis, naive Bayes $\ldots$
  - large number theory for MLE (next time)
    - $P(\vv{\theta}_{\text{ML}})$? or *sampling distribution*
    - does $\vv{\theta}_{\text{ML}}$ change much given another $\mathcal{D}_k = \{\vv{X}_k,\vv{y}_k\}$?



## Topics of today 

Review of probability theory
  
  - univariate Guassian
  
  \bigskip
  
Maximum likelihood estimation in general
  
  - MLE for Gaussian
  - MLE for Bernoulli/Binomial
  <!-- - large number theory of MLE -->
  
  \bigskip
  
Linear regression revisit: MLE
  
  \bigskip
  
Logistic regression and MLE



## Review: Random variable

**Random variable** $X$ 

  - opposite to deterministic variable: $X$ can take a range of value associated with some probability $P(X)$
  - discrete r.v.: if $X$ can only take discrete values
    - e.g. $X\in \{T, F\}$, $X\in \{1,2,3,\ldots\}$ etc.
  - otherwrise $X$ is continuous r.v.
    - e.g. $X\in [0,1]$, $X\in R^2$
    
  <!-- - the distribution $P$ must satisfy -->

  <!-- $$\text{discrete r.v.:  } 0<P(X=x) <1, \text{ and } \sum_{x\in T} P(X=x) =1 $$ -->

  <!-- $$\text{continuous r.v.:  } p(X=x) >0, \text{ and } \int_{x\in T} p(X=x)dx =1$$ -->




  
<!-- $P(X) = \begin{cases} 0.25 & X=0 \\ -->
<!-- 0.5 & X=1 \\ -->
<!-- 0.25 & X=2 \end{cases}$  -->

 
  
  

## Random variable - discrete r.v.
  
If r.v. $X$'s target space $\mathcal{T}$ is discrete

  - $X$ is a **discrete random variable**
  - the probability distribution $P$ is called **probability mass function** (p.m.f.)
  - and $$0\leq P(X=x) \leq 1, \text{ and } \sum_{x\in T} P(X=x) =1$$
  
  
  
## Example - discrete r.v.
  
  **Bernoulli distribution**
  Tossing a coin , $\mathcal{T} = {1, 0}$ (1 is $H$, 0 is $T$), $$P(X=1) = p , P(X=0) = 1-p, 0\leq p\leq 1$$
  
  or  $$P(X=x) = p^{x}(1-p)^{1-x}$$

<!-- ## Example - discrete r.v. -->

<!--   **Binomial distribution** -->
<!--   Tossing a coin $N$ times, the r.v. $Y$ is the number of head shows up -->
<!--   $$P(Y=k) = \binom{N}{k} \cdot p^k(1-p)^{N-k}$$  -->

<!--   - Binomial is a sum of $N$ Bernoulli $X$, $X=\sum_{i=1}^N X_i$ -->




<!-- \begin{columns} -->
<!-- \begin{column}{0.5\textwidth} -->
<!-- ```{r, out.width="99%"} -->
<!--  gbinom(10, 0.3) -->
<!-- ``` -->

<!-- \end{column} -->
<!-- \begin{column}{0.5\textwidth} -->
<!-- ```{r, out.width="99%"} -->
<!--  gbinom(10, 0.5) -->
<!-- ``` -->
<!-- \end{column} -->
<!-- \end{columns} -->

## Example - discrete r.v.
    
**Multinoulli distribution**

  
$X$ can take $\{1, 2, \ldots,k\}$, its probability mass function is 
\begin{columns}
\begin{column}{0.5\textwidth}
$$ P(X) =   \begin{cases} p_1 & X=1 \\
p_2 & X=2 \\
\vdots \\
p_k & X=k
\end{cases}$$

\end{column}
\begin{column}{0.5\textwidth}
$$P(x) = \prod_{i=1}^k p_i^{I(x=i)}$$

$I(x=i) = 1$ if $x=i$ or $0$ if $x\neq i$
\end{column}
\end{columns}


\bigskip

E.g. throw a fair 6-facet die, $\mathcal{T} = {1, 2,\ldots, 6}$, the distribution is 
  $$P(X=i) = 1/6$$  
  
## Random variable - continuous r.v.

If r.v. $X$'s target space $\mathcal{T}$ is continuous
  
  - $X$ is a **continuous random variable **
  - the probability distribution $p$ is called **probability density function** (p.d.f.): note we use $p$
  - and satisfies $$p(x) \geq 0, \text{ and } \int_{x\in T} p(x) dx = 1$$
  - pdf is not probability as $p(x)$ can be greater 1; 
  - calculate probability over an interval: e.g. $$0\leq P(X \in [a,b]) = \int_{a}^b p(x) dx \leq 1$$
  - for $\forall a\in \mathcal{T}$ $P(X=a) = P(X\in [a,a]) =\int_{a}^a p(x) dx=0$  

  
<!-- ## Example - continuous r.v. -->

<!--   **Uniform distribution** -->
<!--   $\mathcal{T} = [0,1]$, $X$ has equal chance to take any value between 0 and 1; the pdf is  -->

<!-- \begin{columns} -->
<!-- \begin{column}{0.5\textwidth} -->
<!-- $$p(x) = \begin{cases} 1 & x\in [0,1] \\ -->
<!-- 0 & \text{otherwise} \end{cases} $$ -->

<!-- \end{column} -->
<!-- \begin{column}{0.5\textwidth} -->
<!-- ```{r, out.width="99%"} -->
<!-- a=0 -->
<!-- b=1 -->
<!-- par(mar=c(4,5,4,0.1)+.1) -->
<!-- curve(dunif(x, min = a, max = b),  -->
<!--       from = -0.5, to = 1.5,  -->
<!--       n = 100000,  -->
<!--       col = "darkblue",  -->
<!--       lwd = 2,  -->
<!--       yaxt = "n", -->
<!--       ylab = 'pdf', cex.lab=2.5, cex.axis=2.5, cex.main=2.5, cex.sub=2.5) -->
<!-- ``` -->
<!-- \end{column} -->
<!-- \end{columns} -->


<!-- Easy to verify $$\int_0^1 p(x)dx = \int_0^1 dx =1$$ -->
<!-- \bigskip -->

<!-- What's the probability that $0<X<0.5$ ?  -->

## Example - continuous r.v.

**Gaussian distribution**
$\mathcal{T} = R$, or $X \in R$ the pdf is

$$p(x) = \normal{x; \mu}{\sigma^2}=\frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{1}{2}(\frac{x-\mu}{\sigma})^2}$$
 $(\frac{x-\mu}{\sigma})^2$ is a distance measure: how far $x$ is away from $\mu$ (measured by $\sigma$ as a unit)

```{r, out.width="65%"}
a=0
b=1
par(mar=c(3,5,3,0.1)+.1)
curve(dnorm(x, mean = 0, sd = 0.5), 
      from = -11, to = 11.5, 
      n = 100000, 
      col = "darkblue", 
      lwd = 2, 
      yaxt = "n",
      xlab="",
      ylab = 'pdf', cex.lab=1.5, cex.axis=1.5, cex.main=1.5, cex.sub=1.5)

curve(dnorm(x, mean = 0, sd = 1), 
      from = -10, to = 10, 
      n = 100000, 
      col = "red", 
      lwd = 2, 
      yaxt = "n",
      add= T,
      ylab = 'pdf', cex.lab=2.5, cex.axis=2.5, cex.main=2.5, cex.sub=2.5)

curve(dnorm(x, mean = 0, sd = 3), 
      from = -10, to = 10, 
      n = 100000, 
      col = "green", 
      lwd = 2, 
      yaxt = "n",
      add= T,
      ylab = 'pdf', cex.lab=2.5, cex.axis=2.5, cex.main=2.5, cex.sub=2.5)

curve(dnorm(x, mean = 5, sd = 1), 
      from = -10, to = 10, 
      n = 100000, 
      col = "darkgreen", 
      lwd = 2, 
      yaxt = "n",
      add= T,
      ylab = 'pdf', cex.lab=2.5, cex.axis=2.5, cex.main=2.5, cex.sub=2.5)

curve(dnorm(x, mean = -5, sd = 1), 
      from = -10, to = 10, 
      n = 100000, 
      col = "gold", 
      lwd = 2, 
      yaxt = "n",
      add= T,
      ylab = 'pdf', cex.lab=2.5, cex.axis=2.5, cex.main=2.5, cex.sub=2.5)

labels <- c(expression(paste(mu, "=0, ", sigma, "=0.5")), expression(paste(mu, "=0, ", sigma, "=1")), expression(paste(mu, "=0, ", sigma, "=3")), expression(paste(mu, "=5, ", sigma, "=1")), expression(paste(mu, "=-5, ", sigma, "=1")))

legend("topright",  title="Gaussians",
  labels, lwd=2, lty=c(1, 1, 1, 1, 1), col=c("darkblue", "red", "green", "darkgreen", "gold"
                                             , cex=3, pt.cex = 3))
```

<!-- ## Question  -->

<!-- Calculate quickly: $$\int_{-\infty}^{\infty} e^{-\frac{1}{2}x^2}dx = ?$$  -->

<!-- \bigskip -->

<!-- For $X\sim \normal{\mu}{\sigma}$, what is $P(X<\mu)=$? -->


## Joint distribution

Ramdom variable $\vv{X} = [X_1, X_2, \ldots, X_n]^T$ can be multidimensional (each $X_i$ is r.v.)
  
  - essentially a *random vector*
  
  \bigskip 
Still satisfies the same requirements
  $$\forall \vv{x}, 0<P(\vv{X}=\vv{x}) <1,\; \sum_{x_1}\sum_{x_2}\ldots\sum_{x_n} P(\vv{X} =[x_1, x_2, \ldots, x_n]) =1$$
  
  - means the probability that ${X} =\vv{x}$ is jointly true
  
<!-- or $$\forall \vv{x}, p(\vv{X}=\vv{x}) >0,\; \int\int\ldots\int p(\vv{X} =\vv{x})d{x_1}d{x_2\ldots dx_{n}} =1$$ -->
\bigskip 

For bivariate case, i.e. $n=2$, $X_1, X_2$ are **independent** (e.g. rolling two dice independently) if 

  $$P(\vv{X}) = P(X_1)P(X_2)$$ 

## Example: joint distribution

The joint distribution of $X$ snow or not, $Y\in$ \{\text{spring}, \text{summer}, \text{autumn}, \text{winter}\} represents the season that $x$ belongs to :
\bigskip 
\begin{table}\centering
\begin{tabular}{ l | c | c | c | c}
   \centering                    
   & $y=\text{Spring}$ & $y=\text{Summer}$ &$y=\text{Autumn}$ & $y=\text{winter}$\\ 
   \hline
  $x= F$ & `r 1/4* 0.2` & `r 1/4* 1` & `r 1/4* 0.3`& `r 1/4* 0`\\
	\hline 
  $x= T$ & `r 1/4* 0.8` & `r 1/4* 0` & `r 1/4* 0.7`& `r 1/4* 1`\\ 
\end{tabular}
\end{table}
\bigskip 
It is easy to verify that    
\[\sum_x\sum_y p(x, y) = 1\]
   
<!-- ## Example: continuous joint distribution -->


<!-- If $X,Y$'s joint p.d.f is  -->
<!-- $$p(x,y) = \frac{1}{2\pi\sigma_x\sigma_y} e^{-\frac{1}{2}[(\frac{x-\mu_x}{\sigma_x})^2 +(\frac{y-\mu_y}{\sigma_y})^2] }$$ -->

<!-- $X,Y$ are bivariate Gaussian distributed  -->

<!-- \bigskip -->
<!-- X,Y are *independent* for this case, why ?  -->



## Probability rules 

There are only two probability rules (integration for continuous r.v.):
\begin{enumerate}
	\item product rule: \[ p(x, y) = p (y|x)p(x) = p(x|y)p(y)\]
	\item sum rule (marginalisation): \[ p (x) = \sum_y p(x, y),\; p(y) = \sum_x p(x, y)\]
\end{enumerate}




## Conditional probability

Conditional probability distribution (by product rule): \[p (x| y) = \frac{p(x, y)}{p(y)}\]
  
  - probability distribution of $x$ conditional on the value of $y$
  
  \bigskip
  
\begin{table}\centering
\begin{tabular}{ l | c | c | c | c}
   \centering                    
   & $y=\text{Spring}$ & $y=\text{Summer}$ &$y=\text{Autumn}$ & $y=\text{winter}$\\ 
   \hline
  $x= F$ & `r 1/4* 0.2` & `r 1/4* 1` & `r 1/4* 0.3`& `r 1/4* 0`\\
	\hline 
  $x= T$ & `r 1/4* 0.8` & `r 1/4* 0` & `r 1/4* 0.7`& `r 1/4* 1`\\ 
\end{tabular}
\end{table}  

\bigskip
- $P(Y= \text{Spring})$ ? use sum rule
  $$P(Y = \text{Spring}) = \sum_{x=\{T,F\}} P(X=x,Y=\text{Spring}) =0.05+0.2=\frac{1}{4}$$
  
- $P(X=T | Y= \text{Spring})$ ?
  $P(X=T | y = \text{Spring}) = \frac{P(x=T, y=\text{Spring})}{P(y=\text{Spring})}=\frac{0.2}{0.25}=`r 0.2/0.25`$
<!-- The total probability rule also implies marginalization rule:\[ p (x) = \sum_y p(x, y) \] -->

<!-- Baye's theorem is then just a combination of the above three rules: \[ p (x| y) = \frac{p(y|x) p(x)}{\sum_x p(y|x) p(x)}\] -->



<!-- ## Expectation and variance -->

<!-- **Expection** of a r.v. is defined as  -->
<!-- $$\E{g(X)} = \sum_x g(x) P(x) \text{ or } \E{g(X)} = \int g(x) P(x)dx$$ -->

<!-- - $\E{a} = a$, $a$ is a constant (not r.v.) -->
<!-- - $\E{\E{X}} = \E{X}$ -->
<!-- - $\E{aX +bY}  = a\E{X} + b\E{Y}$: linearity -->

<!-- \bigskip -->

<!-- **Variance** of a r.v. is defined as -->
<!-- $$\Var{g(X)} = \E{(g(X)-\E{g(X)})^2}$$  -->

<!-- - $\Var{X} = \E{X^2} - \E{X}^2$ -->
<!-- - $\Var{aX} = a^2\Var{X}$ -->

<!-- \bigskip -->

<!-- *Prove them or convince yourself !* -->
<!-- \only<article>{A very useful identity that links expectation and variance together is  -->
<!-- \[\Var{x} = \E{x^2} - \E{x}^2 , \] which can be proved as follows: -->
<!-- \[ \Var{x} = \E{x^2 -2\E{x} x + \E{x}^2} = \E{x^2} -2\E{x}^2 + \E{x}^2 = \E{x^2} - \E{x}^2; \] -->
<!--  the second equality holds because $\E{x}=\mu$  is a constant. Note that $\E{x^2}$ is called the \textit{second moment} of r.v. $x$.} -->


<!-- ## Example -->

<!-- $X$ is a Bernoulli r.v. with parameter $p=0.5$; what is $\E{X}$? -->

<!-- - $\E{X} = 1\times P(X=1) + 0\times P(X=0) = p =0.5$; -->

<!-- \bigskip -->

<!-- $Y$ is a Binomial r.v. with $N=10, p=0.5$, what is $\E{Y}$? -->

<!-- - $Y= \sum_{i=1}^{N} X = N\times X$ -->
<!-- - $\E{Y} = \E{N\times X} = N\times \E{X} = N\times p = 5$ -->
<!-- - interpretation: you expect to see 5 successes out of 10 (on average the result is 5 if you repeat the experiment a lot of times) -->



## Parameter estimation problem 

Given dataset $\mathcal{D} =\{\di{y}{1}, \di{y}{2},\ldots,\di{y}{m}\}$, and assume $$\di{y}{i} {\sim}  P(\di{y}{i}| \theta), \;  i=1,\ldots, m$$

  - *parameter estimation*: given $\mathcal{D}$, what is $\theta$?

\bigskip

For example, throw the same coin $n$ times and record value $\di{y}{i}\in \{1,0\}, i=1,\ldots,m$
 $$P(\di{y}{i}|\theta) = Ber(\theta)$$
  
  - $\di{y}{i} \stackrel{iid}{\sim} Ber(\theta)$: independent and identically distributed
  - $\theta$: the probability that head turns up

  

## Maximum Likelihood Estimation

Likelihood function: $P(\mathcal{D}|\theta)= \prod_i^m p(\di{y}{i}|\theta)$

  - the probability of observing data $\mathcal{D}$ given $\theta$
  - it is not a probability distribution for $\theta$:
  $\int p(\mathcal{D}|\theta) d\theta \neq 1$
  - but it is a function of $\theta$ (given $\mathcal{D}$)
  
\bigskip

Maximum likelihood estimation:

$$\theta_{ML} = \argmax_{\theta} P(\mathcal{D}|\theta)$$

  - the value $\theta$ most likely to have generated the data 
  
\bigskip

We usually deal with log-likelihood, denoted as $\mathcal{L}(\theta)$

$$\theta_{ML} = \argmax_{\theta} \underbrace{\log P(\mathcal{D}|\theta)}_{\mathcal{L}(\theta)}= \argmax_{\theta} P(\mathcal{D}|\theta)$$
  <!-- - notation: $\mathcal{L}$ for log likelihood function; $L$ for loss function -->

## MLE for Bernoulli

```{r}
loglikBer <-function(n, r, theta){
  r*log(theta) + (n-r)*log(1-theta)
}
```

For the Bernoulli case: $\di{y}{i} \in \{1,0\}$
  \begin{align}
  \mathcal{L}(\theta) &= \log P(\mathcal{D}|\theta) = \log \prod_{i=1}^m P(\di{y}{i}; \theta)\nonumber \\
  &=  \log \prod_{i=1}^m \theta^{\di{y}{i}}(1-\theta)^{1-\di{y}{i}} \label{eq:berlik}\\
  &= \log (\theta^{\sum_{i=1}^m \di{y}{i}}(1-\theta)^{\sum_{i=1}^m (1-\di{y}{i})}) \nonumber\\
  &= \sum_{i=1}^m \di{y}{i} \log\theta + (m- \sum_{i=1}^m \di{y}{i}) \log (1-\theta) \nonumber\\
  &= R \log\theta + (m- R) \log (1-\theta) \nonumber
  \end{align}
  
  - $R=\sum_i^m \di{y}{i}$: the total count of heads
  - we will use the likelihood function eq.(\ref{eq:berlik}) for logistic regression later

## Some plots of (scaled) likelihood 

\begin{columns}
\begin{column}{0.5\textwidth}
```{r, out.width="100%"}
thetas <- seq(0, 1, by = 0.01)
lik <- loglikBer(20,10, thetas)
plot(thetas, exp(lik)/max(exp(lik)), type = 'l', main = "M=20, R=10; M(blue)=100 R(blue)=50;M(red)=200, R(red)=100", cex.main=1.2)
logl2 <- loglikBer(200,100, thetas)
lines(thetas, exp(logl2)/max(exp(logl2)), col="red")
logl2 <- loglikBer(100,50, thetas)
lines(thetas, exp(logl2)/max(exp(logl2)), col="blue")
#plot(thetas, exp(logl2), col="red")
```


 $m=20; R=\sum x_i=10$
 \textcolor{blue}{$m=100; R=\sum{x_i}=50$}
 \textcolor{red}{$m=200; R=\sum{x_i}=100$}
  
  
\end{column}
\begin{column}{0.5\textwidth}
```{r, out.width="100%"}
thetas <- seq(0, 1, by = 0.01)
lik <- loglikBer(40,20, thetas)
plot(thetas, exp(lik)/max(exp(lik)), type = 'l', main = "N=20, R=5; N=20, R=15", cex.main=1.2)
lik <- loglikBer(40,5, thetas)
lines(thetas, exp(lik)/max(exp(lik)), type = 'l', col="blue")
lik <- loglikBer(40,35, thetas)
lines(thetas, exp(lik)/max(exp(lik)), type = 'l', col="red")
```
 $m=40; R=\sum x_i=20$
 \textcolor{blue}{$m=40; R=\sum{x_i}=5$}
 \textcolor{red}{$m=40; R=\sum{x_i}=35$}
\end{column}

\end{columns}


## MLE for Bernoulli

Take the derivative $\frac{d\mathcal{L}(\theta)}{d\theta}$ and set it to zero 

\begin{align*}
\mathcal{L}(\theta)&= R \log\theta + (m- R) \log (1-\theta) \\
\frac{dL}{d\theta} &= \frac{R}{\theta} - \frac{m-R}{1-\theta} =0 \\
&\Rightarrow \theta_{ML}= \frac{R}{m}
\end{align*}
  
  - note $R=\sum_{i=1}^m \di{y}{i}$ is the count of heads; 
  - $m$ is the total count
  - $\theta_{ML}$ is just the relative frequency 


## Gradient ascent (descent) ?

We can also apply gradient **ascent** (why ascent?): 

loop until converge:
$$\theta_{t+1} \leftarrow \theta_{t} + \alpha \nabla_{\theta}\mathcal{L}(\theta_t)$$ 

  - where $$\nabla_{\theta} \mathcal{L}(\theta) = \frac{R}{\theta} - \frac{m-R}{1-\theta}$$
  
or gradient descent with negative log likelihood $N\mathcal{L}(\theta)=-\mathcal{L}(\theta)$: $$\theta_{t+1} \leftarrow \theta_{t} - \alpha \nabla_{\theta}(N\mathcal{L}(\theta_t))$$
  
  - but $\theta \in [0,1]$: constrained optimisation
  - the gradient $\nabla_{\theta} \mathcal{L}(\theta)$ is not defined at $\theta = 0, 1$ !  
  - difficult to converge if step outside: $\theta_t \geq 1; \theta_t\leq 0$

## Reparameterisation trick for gradient descent (ascent)

Reparameterisation trick: find $f$ $$\theta = f(\beta), \; \text{such that}$$ 

  - $\beta \in R$ and write $\mathcal{L}(\theta) = \mathcal{L}(f(\beta))$
  - use chain rule to find $\nabla_{\beta}\mathcal{L}(\beta) = \nabla_{\theta}\mathcal{L}\cdot\nabla_{\beta}f(\beta)$
  - gradient ascent against $\beta$; then transform back
  
$$
  \beta_{t+1} \leftarrow \beta_{t} + \alpha \nabla_{\beta}\mathcal{L}(\beta_t);\;\; \theta_{t+1} \leftarrow f(\beta_{t+1}) 
$$

\bigskip

For example, if $\theta > 0$, then $$\theta = f(\beta) = e^{\beta}, \text{ the new gradient is then}$$

$$\nabla_{\beta}\mathcal{L}(\beta) = \nabla_{\theta}\mathcal{L}\cdot e^{\beta}$$

## Reparameterisation trick for Bernoulli MLE

For $\theta \in [0,1]$, such a function is sigmoid:


\begin{columns}
\begin{column}{0.4\textwidth}
$$\sigma(x) = \frac{1}{1+e^{-x}} = \frac{e^x}{e^x+1};$$
The derivative: 
$$\frac{d\sigma(x)}{dx} = \sigma(x)(1-\sigma(x))$$
\end{column}

\begin{column}{0.6\textwidth}
```{r, out.width='100%'}
par(mar=c(5,5,3,0.1)+.1)
par(cex.lab=2, cex.main=2, cex.axis=2)
curve(1/(1+exp(-1*x)), from =-8, to =8, xlab = "x", ylab = "Sigmoid", col="red")
```
\end{column}
\end{columns}

## Reparameterisation trick for Bernoulli MLE

For the Bernoulli case, reparameterize $\theta$: $$\theta = \sigma(\beta);$$ 

Rewrite the log likelihood $\mathcal{L}$ as a function of $\beta$:

$$\mathcal{L}(\beta) = \log \prod_{i=1}^m \theta^{\di{y}{i}}(1-\theta)^{1-\di{y}{i}}= \log \prod_{i=1}^m \sigma(\beta)^{\di{y}{i}}(1-\sigma(\beta))^{1-\di{y}{i}}$$ 
The gradient of $L$ w.r.t $\beta$ is

$$\nabla_\beta \mathcal{L}(\beta) = \nabla_{\theta} \mathcal{L} \cdot \nabla_\beta{\theta} = \left(\frac{R}{\sigma} - \frac{m-R}{1-\sigma}\right)\sigma(1-\sigma)$$

## Code (R like syntax)

```{r, eval=FALSE, echo=TRUE}
grad <- function(m,r,beta){
  sig <- sigmoid(beta)
  g <- (r/sig - (m-r)/(1-sig))*sig*(1-sig)
  return(g)
}

berGAscent <- function(alpha, iter, m, r, beta0){
  betas <- vector(mode="numeric", length = iter+1)
  betas[1] <- beta <- beta0
  for(i in 1:iter){
    g <- grad(m,r,beta)
    betas[i+1] <- beta <- beta + alpha*g
  }
  return(betas)
}
```



## Example with $m=100, R=25, \theta_{ML} = 0.25, \alpha=0.01$

```{r, out.width="100%"}
library(pracma)
N <- 40;
R <- 5;

inverseSigm <- function(theta){
  log(theta/(1-theta))
}

berGrad <- function(n,r, beta){
  sigValue <- sigmoid(beta)
  (r/sigValue - (n-r)/(1-sigValue))*sigValue*(1-sigValue)
}


berNDescent <- function(alpha, iter, n, r, beta0){
  beta <- beta0
  beta_history <- vector(mode="numeric", length = iter+1)
  beta_history[1] <- beta
  for(i in 1:iter){
    grad <- berGrad(n,r,beta)
    beta <- beta + alpha*grad
    beta_history[i+1] <- beta
  }
  return(beta_history)
}
par(mar=c(5,5,3,0.1)+.1)
par(mfrow=c(2,1))
iter=75
tr1 <- (berNDescent(0.01, iter, 100, 25, 0))
tr2<-(berNDescent(0.01, iter, 100, 25, -5))
tr3<-(berNDescent(0.01, iter, 100, 25, 5))
plot(tr1,type="l", ylim=c(-6,6), cex.lab=2, xlab="iteration", ylab=expression(paste(beta)), lty=2, lwd=4)
lines(tr2, col="red", lty=2, lwd=4)
lines(tr3, col="blue", lty=2, lwd=4)
labels <- c("beta0 = 0", "beta0 = -5", "beta0 = 5");
legend("topright",  title=expression(paste(beta, "=-1.1")),
  labels, lwd=2, lty=c(1, 1, 1), col=c("black", "red", "blue", cex=3, pt.cex = 3))

plot(sigmoid(tr1),type="l", ylim=c(0,1), cex.lab=2, xlab="iteration", ylab=expression(theta), lty=2, lwd=4)
lines(sigmoid(tr2), col="red", lty=2, lwd=4)
lines(sigmoid(tr3), col="blue", lty=2, lwd=4)
labels <- c("theta0 = 0.5", "theta0 = 0.006", "theta0 = 0.99");
legend("topright",  title=expression(paste(theta, "=0.25")),
  labels, lwd=2, lty=c(1, 1, 1), col=c("black", "red", "blue", cex=3, pt.cex = 3))

```



## MLE for Gaussian

Similarly, for Gaussian $\mathcal{D}=\{\di{y}{1}, \ldots, \di{y}{m}\}$, the parameters are $\vv{\theta} = \{\mu, \sigma^2\}$ and

$$p(\di{y}{i}; \mu, \sigma^2) = \Gaussian{\di{y}{i}}{\mu}{\sigma}$$

therefore, the log likelihood for $\di{y}{i}$ is: $$\log p(\di{y}{i}; \mu, \sigma^2) = -\frac{1}{2} \log(2\pi\sigma^2) -\frac{1}{2\sigma^2}\underbrace{(\di{y}{i}-\mu)^2}_{\text{squared error!}}$$


##

  \begin{align}
  \mathcal{L}(\mu, \sigma^2) &= \log p(\mathcal{D}|\mu, \sigma^2) = \log \prod_{i=1}^m p(\di{y}{i}; \mu, \sigma^2) = \sum_{i=1}^m \log p(\di{y}{i};\mu, \sigma^2)  \nonumber \\ &= \sum_{i=1}^m \left(-\frac{1}{2} \log(2\pi\sigma^2) -\frac{(\di{y}{i}-\mu)^2}{2\sigma^2}\right ) \nonumber \\
  &= -\frac{m}{2}\log(2\pi \sigma^2)- \frac{1}{2\sigma^2} \underbrace{\sum_{i=1}^m (\di{y}{i}-\mu)^2}_{\text{sum of squared error}} \nonumber
  \end{align}

Take (partial) derivative and set to zero (verify yourself!):
$$\frac{\partial L}{\partial \mu} =  \frac{1}{\sigma^2} \left (\sum_{i=1}^m (\di{y}{i}-\mu)\right) = 0; \;
\frac{\partial L}{\partial \sigma^2} =-\frac{m}{2\sigma^2} +\frac{\sum_{i=1}^m(\di{y}{i} -\mu)^2}{2(\sigma^2)^2}  = 0$$

\begin{align*} 
\Rightarrow \begin{cases} \mu_{ML} = \frac{1}{m}\sum_{i=1}^m \di{y}{i} \;\; \leftarrow \text{ sample mean!} \\
\sigma^2_{ML} = \frac{1}{m}\sum_{i=1}^m(\di{y}{i}-\mu_{ML})^2
\end{cases}
\end{align*}


<!-- ## Large sample theory for ML -->




## Linear regression: revisit

Linear regression model: 
$$y^{(i)} =\vv{\theta}^T\vv{x}^{(i)}  + e^{(i)}$$
  
  - $i = 1,\ldots,m$: index of data samples (row index), 
  - $\vv{x}^{(i)} = [1, x_{1}^{(i)}, \ldots, x^{(i)}_n]^T$ is a $(n+1) \times 1$ vector: 
    - $n$: number of predictors (columns)
  - $\vv{\theta}$ is the model parameter
  - $e^{(i)}$ is the prediction difference
  
Assume $$\di{e}{i} \sim \normal{0}{\sigma^2}$$

  - the prediction error is Gaussian distributed
  - the mean of the error is $0$
  - the variance is $\sigma^2$, which needs to be estimated 
  
## Linear regression: revisit 

$$\di{e}{i}  \sim \normal{0}{\sigma^2}$$
$$\Downarrow$$

$$\di{y}{i}=\vv{\theta}^{T} \di{\vv{x}}{i} + \di{e}{i}  \sim \normal{\vv{\theta}^{T} \di{\vv{x}}{i}}{\sigma^2}$$

$$\Downarrow$$


$$p(\di{y}{i}|\vv{\theta},\sigma^2, \di{\vv{x}}{i}) = \frac{1}{\sqrt{2\pi\sigma^2}}\text{exp}\left(-\frac{(\di{y}{i}-\vv{\theta}^T\di{\vv{x}}{i})^2}{2\sigma^2}\right)$$
$$\Downarrow$$

$$\mathcal{L}(\vv{\theta},\sigma^2) = \log p(\mathcal{D} |\vv{\theta}, \sigma^2) = \log p(\vv{y} |\vv{\theta},\sigma^2,\vv{X})= \log \prod_{i=1}^m p(\di{y}{i};\vv{\theta},\di{\vv{x}}{i})$$


## Linear regression: maximum likelihood estimation

The log likelihood function is:
\begin{align*}
\mathcal{L}(\vv{\theta}, \sigma^2) &= \log \prod_{i=1}^m p(\di{y}{i};\vv{\theta},\di{\vv{x}}{i}) \\
&= \sum_{i=1}^m \log p(\di{y}{i};\vv{\theta},\di{\vv{x}}{i}) \\
&= -\frac{m}{2}\log(2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^m (\di{y}{i} - \vv{\theta}^T\di{\vv{x}}{i})^2
\end{align*}

\bigskip

Maximising $\mathcal{L}$ w.r.t $\vv{\theta}$ is the same as minimising loss function $$L(\vv{\theta})=\sum_{i=1}^m (\di{y}{i} - \vv{\theta}^T\di{\vv{x}}{i})^2$$
  
   $$\Rightarrow \vv{\theta}_{ML} = \vv{\theta}_{LS}$$


## Logistic regression

Let's consider binary classification $\di{y}{i} \in \{1,0\}$, assume Bernoulli likelihood

$$P(y^{(i)}=1) = \sigma\left (\vv{\theta}^T\vv{x}^{(i)}\right )$$
  
  - $i = 1,\ldots,m$: index of data samples (row index)
  - $\vv{\theta}^T\di{\vv{x}}{i}= \theta_0 + \theta_1\di{x_1}{i}+\ldots+ \theta_n\di{x_n}{i}\in R$
  - $\sigma(x) \in [0,1]$
  - $\vv{\theta}$ is the model parameter

  
The log likelihood function is 

$$\mathcal{L}(\vv{\theta}) = \underbrace{\log \prod_{i=1}^m \sigma^{\di{y}{i}} (1-\sigma)^{1-\di{y}{i}}}_{\text{the same as Bernoulli model with } \theta}$$

  - replace single parameter $\sigma(\beta)$ with $\sigma(\vv{\theta}^T\di{\vv{x}}{i})$
  - $\beta$ serves the same purpose as $\theta_0$: the intercept (cf. page 22)



## Logistic regression: geometric view

$$\sigma(\vv{\theta}^T\vv{x})$$

  - $\vv{\theta}^T\vv{x}$ is a hyperplane
  - $\sigma(\vv{\theta}^T\vv{x})$  squeeze the plane between $(0, 1)$
  - $\vv{\theta}$ determines the direction of surface facing
  - $||\vv{\theta}||_2^2$ determines the steepness
  
##

\begin{figure}
    \centering
    \includegraphics[width = 0.85\textwidth]{./figs/figure260.eps}\footnote{Information theory, inference and learning algorithms, David MacKay}
 % \caption{Awesome figure}
\end{figure}
<!-- ```{python, out.width="80%"} -->
<!-- import numpy as np -->
<!-- import matplotlib.pyplot as plt -->

<!-- theta1 = 0.5 -->
<!-- theta2 = 0.5 -->
<!-- def sig(x): -->
<!--   return 1 / (1 + np.exp(-x)) -->

<!-- vsig = np.vectorize(sig); -->

<!-- x1,y1 = np.meshgrid(np.linspace(-10,10,10),np.linspace(-10,10,10)) -->

<!-- x1 = np.multiply(x1, theta1) -->

<!-- y1 = np.multiply(y1, theta2) -->
<!-- xy = np.add(x1,y1) -->
<!-- sigM = vsig(xy) -->
<!-- # np.add(x1+y1) -->
<!-- u = np.multiply(sigM, np.add(1,-sigM)) * theta1 -->
<!-- v = np.multiply(sigM, np.add(1,-sigM)) * theta2 -->
<!-- #  -->
<!-- plt.quiver(x,y,u,v) -->
<!-- plt.show() -->
<!-- ``` -->


## Summary

Maximum likelihood estimation 

  - gives rise to squared error loss function for regression
    - sample mean is the simplest kind of linear regression where $x^{(i)}=1$ for all $i=1,\ldots,m$
 
    
  - gives rise to logistic error (cross-entropy) for classification 
    - relative frequency is the simpliest kind of logistic regression where $x^{(i)}=1$ for all $i=1,\ldots,m$





## Suggested reading and exercises

Reading 

  - MLAPP 2.2, 2.3.1, 2.3.2, 2.4.1, 7.3, 8.1-8.3.1
  - DL 3, 5.5, 5.7.1
  - Information theory, inference and learning algorithms by David MacKay, chapter 2, 22.1, 39.1, 39.2
  
\bigskip

Exercise

  - go through the equations
  - write gradient descent for Gaussian model's likelihood function
    - generate some artifical data
    - workout the gradients
    - use the reparameterisation trick to treat $\sigma^2 >0$
    - check whether they converge 
    
  - derive the gradient for logistic regression's log likelihood function

  
## Next time

  - Large number theory of MLE
  
    $$\theta_{ML} \rightarrow \mathcal{N}(\theta, I_m^{-1}(\theta))$$
      - ML estimator can recover the true parameter $\theta$
      - as data size ${m\rightarrow \infty}$
      
  - gradient descent of logistic regression
  - Newton's method for optimisation
  
## *Random variable: formal aspects 

Formally, r.v. $X$ is a mapping from *sample space* $\Omega$ to *target space* $\mathcal{T}$
  
  - $\Omega$: all possible outcomes of an experiment
  - $\mathcal{T}$: possible values $X$ can take
  - events $E\subseteq \Omega$
  - $X(\omega) \in \mathcal{T}, \forall \omega \in \Omega$
  - $X^{-1}$ defines a partition of $\Omega$
  <!-- - Given $t\in \mathcal{T}$: reverse mapping $X^{-1}(t) = E_{t}= \{\omega: X(\omega) =t\}\subseteq \Omega$ -->
 

Example: toss a fair coin twice, r.v. $X$: \# of heads turned up

  - the *sample space* is $\Omega =\{HH, TT, HT, TH\}$
  - *target space* is $T =\{0,1,2\}$
  - $X(HH) = 2; X(HT)=X(TH)=1; X(TT) =0$
  - $X^{-1} = \{E_0, E_1, E_2\}$ defines a parition of $\Omega$: $E_0=\{TT\}, E_1=\{TH,HT\}, E_2=\{HH\}$
    - disjoint: $E_0 \cap E_1 = E_0 \cap E_2= E_1 \cap E_2 = \emptyset$
    - complete: $E_0 \cup E_1 \cup E_2 = \Omega$
